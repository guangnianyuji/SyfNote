{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_attribute_name\n",
      "Season\n",
      "-\\frac{3}{12}log_2(\\frac{3}{12})\n",
      "-\\frac{9}{12}log_2(\\frac{9}{12})\n",
      "ent\n",
      "0.8112781244591328\n",
      "Autumn\n",
      "占比\n",
      "\\frac{2}{12}\n",
      "-\\frac{2}{2}log_2(\\frac{2}{2})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "Spring\n",
      "占比\n",
      "\\frac{2}{12}\n",
      "-\\frac{1}{2}log_2(\\frac{1}{2})\n",
      "-\\frac{1}{2}log_2(\\frac{1}{2})\n",
      "ent\n",
      "1.0\n",
      "0.16666666666666666\n",
      "Summer\n",
      "占比\n",
      "\\frac{3}{12}\n",
      "-\\frac{2}{3}log_2(\\frac{2}{3})\n",
      "-\\frac{1}{3}log_2(\\frac{1}{3})\n",
      "ent\n",
      "0.9182958340544896\n",
      "0.2295739585136224\n",
      "Winter\n",
      "占比\n",
      "\\frac{5}{12}\n",
      "-\\frac{5}{5}log_2(\\frac{5}{5})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "split_attribute_name: Season Weighted_Entropy: 0.396240625180289\n",
      "split_attribute_name\n",
      "After 8:00\n",
      "-\\frac{3}{12}log_2(\\frac{3}{12})\n",
      "-\\frac{9}{12}log_2(\\frac{9}{12})\n",
      "ent\n",
      "0.8112781244591328\n",
      "No\n",
      "占比\n",
      "\\frac{7}{12}\n",
      "-\\frac{1}{7}log_2(\\frac{1}{7})\n",
      "-\\frac{6}{7}log_2(\\frac{6}{7})\n",
      "ent\n",
      "0.5916727785823275\n",
      "0.34514245417302436\n",
      "Yes\n",
      "占比\n",
      "\\frac{5}{12}\n",
      "-\\frac{2}{5}log_2(\\frac{2}{5})\n",
      "-\\frac{3}{5}log_2(\\frac{3}{5})\n",
      "ent\n",
      "0.9709505944546686\n",
      "0.4045627476894453\n",
      "split_attribute_name: After 8:00 Weighted_Entropy: 0.7497052018624697\n",
      "split_attribute_name\n",
      "Wind\n",
      "-\\frac{3}{12}log_2(\\frac{3}{12})\n",
      "-\\frac{9}{12}log_2(\\frac{9}{12})\n",
      "ent\n",
      "0.8112781244591328\n",
      "Breeze\n",
      "占比\n",
      "\\frac{5}{12}\n",
      "-\\frac{5}{5}log_2(\\frac{5}{5})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "Gale\n",
      "占比\n",
      "\\frac{3}{12}\n",
      "-\\frac{2}{3}log_2(\\frac{2}{3})\n",
      "-\\frac{1}{3}log_2(\\frac{1}{3})\n",
      "ent\n",
      "0.9182958340544896\n",
      "0.2295739585136224\n",
      "No Wind\n",
      "占比\n",
      "\\frac{4}{12}\n",
      "-\\frac{1}{4}log_2(\\frac{1}{4})\n",
      "-\\frac{3}{4}log_2(\\frac{3}{4})\n",
      "ent\n",
      "0.8112781244591328\n",
      "0.2704260414863776\n",
      "split_attribute_name: Wind Weighted_Entropy: 0.5\n",
      "Node split on feature Season with gain 0.4150374992788438\n",
      "value Autumn\n",
      "value Spring\n",
      "split_attribute_name\n",
      "After 8:00\n",
      "-\\frac{1}{2}log_2(\\frac{1}{2})\n",
      "-\\frac{1}{2}log_2(\\frac{1}{2})\n",
      "ent\n",
      "1.0\n",
      "No\n",
      "占比\n",
      "\\frac{1}{2}\n",
      "-\\frac{1}{1}log_2(\\frac{1}{1})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "Yes\n",
      "占比\n",
      "\\frac{1}{2}\n",
      "-\\frac{1}{1}log_2(\\frac{1}{1})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "split_attribute_name: After 8:00 Weighted_Entropy: 0.0\n",
      "split_attribute_name\n",
      "Wind\n",
      "-\\frac{1}{2}log_2(\\frac{1}{2})\n",
      "-\\frac{1}{2}log_2(\\frac{1}{2})\n",
      "ent\n",
      "1.0\n",
      "Breeze\n",
      "占比\n",
      "\\frac{1}{2}\n",
      "-\\frac{1}{1}log_2(\\frac{1}{1})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "No Wind\n",
      "占比\n",
      "\\frac{1}{2}\n",
      "-\\frac{1}{1}log_2(\\frac{1}{1})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "split_attribute_name: Wind Weighted_Entropy: 0.0\n",
      "Node split on feature After 8:00 with gain 1.0\n",
      "value No\n",
      "value Yes\n",
      "value Summer\n",
      "split_attribute_name\n",
      "After 8:00\n",
      "-\\frac{2}{3}log_2(\\frac{2}{3})\n",
      "-\\frac{1}{3}log_2(\\frac{1}{3})\n",
      "ent\n",
      "0.9182958340544896\n",
      "No\n",
      "占比\n",
      "\\frac{2}{3}\n",
      "-\\frac{1}{2}log_2(\\frac{1}{2})\n",
      "-\\frac{1}{2}log_2(\\frac{1}{2})\n",
      "ent\n",
      "1.0\n",
      "0.6666666666666666\n",
      "Yes\n",
      "占比\n",
      "\\frac{1}{3}\n",
      "-\\frac{1}{1}log_2(\\frac{1}{1})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "split_attribute_name: After 8:00 Weighted_Entropy: 0.6666666666666666\n",
      "split_attribute_name\n",
      "Wind\n",
      "-\\frac{2}{3}log_2(\\frac{2}{3})\n",
      "-\\frac{1}{3}log_2(\\frac{1}{3})\n",
      "ent\n",
      "0.9182958340544896\n",
      "Breeze\n",
      "占比\n",
      "\\frac{1}{3}\n",
      "-\\frac{1}{1}log_2(\\frac{1}{1})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "Gale\n",
      "占比\n",
      "\\frac{2}{3}\n",
      "-\\frac{2}{2}log_2(\\frac{2}{2})\n",
      "ent\n",
      "-0.0\n",
      "-0.0\n",
      "split_attribute_name: Wind Weighted_Entropy: 0.0\n",
      "Node split on feature Wind with gain 0.9182958340544896\n",
      "value Breeze\n",
      "value Gale\n",
      "value Winter\n",
      "\n",
      "Tree:\n",
      "{'Season': {'Autumn': 'Yes', 'Spring': {'After 8:00': {'No': 'Yes', 'Yes': 'No'}}, 'Summer': {'Wind': {'Breeze': 'Yes', 'Gale': 'No'}}, 'Winter': 'Yes'}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'Season': ['Spring', 'Winter', 'Autumn', 'Winter', 'Summer', 'Winter', 'Winter', 'Winter', 'Spring', 'Summer', 'Summer', 'Autumn'],\n",
    "    'After 8:00': ['No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes'],\n",
    "    'Wind': ['Breeze', 'No Wind', 'Breeze', 'No Wind', 'Breeze', 'Breeze', 'Gale', 'No Wind', 'No Wind', 'Gale', 'Gale', 'Breeze'],\n",
    "    'Sleep in': ['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate entropy\n",
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    entropy = -np.sum([(counts[i] / np.sum(counts)) * np.log2(counts[i] / np.sum(counts)) for i in range(len(elements))])\n",
    "    for i in range (len(elements)):\n",
    "        print(f\"-\\\\frac{{{counts[i]}}}{{{np.sum(counts)}}}log_2(\\\\frac{{{counts[i]}}}{{{np.sum(counts)}}})\")\n",
    "    print(\"ent\")\n",
    "    print(entropy)\n",
    "    return entropy\n",
    "\n",
    "# Calculate information gain\n",
    "def InfoGain(data, split_attribute_name, target_name=\"Sleep in\"):\n",
    "    print(\"split_attribute_name\")\n",
    "    print(split_attribute_name)\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    vals, counts= np.unique(data[split_attribute_name], return_counts=True)\n",
    "    \n",
    "    Weighted_Entropy = 0\n",
    "    for i in range(len(vals)):\n",
    "       \n",
    "       f1=counts[i]/np.sum(counts)\n",
    "       print(vals[i])\n",
    "       print(\"占比\")\n",
    "       print(f\"\\\\frac{{{counts[i]}}}{{{np.sum(counts)}}}\")\n",
    "       f2=entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name])\n",
    "       \n",
    "       print(f1*f2)\n",
    "       Weighted_Entropy += f1*f2\n",
    "    print(\"split_attribute_name:\",split_attribute_name,\"Weighted_Entropy:\",Weighted_Entropy)\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain, total_entropy, Weighted_Entropy\n",
    "\n",
    "# Function to build decision tree\n",
    "def build_tree(data, originaldata, features, target_attribute_name=\"Sleep in\", parent_node_class = None):\n",
    "    # If all target_values have the same value, return this value\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "\n",
    "    # If the dataset is empty, return the mode target feature value of the original dataset\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name], return_counts=True)[1])]\n",
    "\n",
    "    # If the feature space is empty, return the mode target feature value of the dataset\n",
    "    elif len(features) == 0:\n",
    "        return parent_node_class\n",
    "\n",
    "    else:\n",
    "        # Set the default value for this node --> The mode target feature value of the dataset\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
    "        \n",
    "        # Select the feature which best splits the dataset\n",
    "        item_values = [InfoGain(data, feature, target_attribute_name) for feature in features] # Return the information gain values for the features in the dataset\n",
    "        \n",
    "        best_feature_index = np.argmax([item[0] for item in item_values]) # Index of the best feature\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        # Print the node decision\n",
    "        print(f\"Node split on feature {best_feature} with gain {item_values[best_feature_index][0]}\")\n",
    "\n",
    "        # Create the tree structure\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        # Remove the feature with the best info gain\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        # Grow a branch under the root node for each possible value of the root node feature\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            print(\"value\",value)\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            \n",
    "            # Call the build_tree function\n",
    "            subtree = build_tree(sub_data, df, features, target_attribute_name, parent_node_class)\n",
    "            \n",
    "            # Add the sub tree\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return tree\n",
    "\n",
    "features = df.columns[:-1].tolist()\n",
    "tree = build_tree(df, df, features)\n",
    "print(\"\\nTree:\")\n",
    "print(tree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
